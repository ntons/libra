---
# Source: libra/charts/apiproxy/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: apiproxy
  namespace: libra
data:
  cds.yaml: |+
    resources:
    - name: cluster_librad_v1
      "@type": type.googleapis.com/envoy.config.cluster.v3.Cluster
      connect_timeout: 0.2s
      http2_protocol_options: {}
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: cluster_librad_v1
        endpoints:
        - lb_endpoints:
          - endpoint:
              address:
                socket_address:
                  address: librad-0-0-1.libra.svc.cluster.local
                  port_value: 80
      #health_checks:
      #- timeout: 0.2s
      #  interval: 1s
      #  healthy_threshold: 1
      #  unhealthy_threshold: 3
      #  grpc_health_check: {}
  
  envoy.yaml: |+
    node:
      id: apiproxy
      cluster: cluster_apiproxy
    admin:
      access_log_path: "/dev/null"
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 8000
    dynamic_resources:
      cds_config:
        path: /etc/envoy/cds.yaml
      lds_config:
        path: /etc/envoy/lds.yaml
  
  lds.yaml: |+
    resources:
    - name: listener_apiproxy
      "@type": type.googleapis.com/envoy.config.listener.v3.Listener
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 80
      filter_chains:
      - filters:
        - name: envoy.filters.network.http_connection_manager
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
            stat_prefix: listener_apiproxy
            access_log:
              name: envoy.access_loggers.file
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
                path: /dev/stdout
            route_config:
              name: route_apiproxy
              virtual_hosts:
              - name: route_apiproxy
                domains:
                - "*"
                routes:
                - match:
                    #prefix: '/libra.v1.'
                    safe_regex:
                      google_re2: {}
                      # \w stand for [0-9a-zA-Z]
                      regex: '/libra\.v1\.\w+/.*'
                    grpc: {}
                  route:
                    cluster: cluster_librad_v1
                    idle_timeout: 5s # must be disabled for long-lived and streaming requests
            http_filters:
            - name: envoy.filters.http.ext_authz
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthz
                grpc_service:
                  envoy_grpc:
                    cluster_name: cluster_librad_v1
                  initial_metadata:
                  - key: "x-libra-auth-by"
                    value: "secret"
                  timeout: 0.5s
                transport_api_version: V3
            - name: envoy.filters.http.router
---
# Source: libra/charts/edgeproxy/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: edgeproxy
  namespace: libra
data:
  cds.yaml: |+
    resources:
    - name: cluster_librad_v1
      "@type": type.googleapis.com/envoy.config.cluster.v3.Cluster
      connect_timeout: 0.2s
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: cluster_librad_v1
        endpoints:
        - lb_endpoints:
          - endpoint:
              address:
                socket_address:
                  address: librad-0-0-1.libra.svc.cluster.local
                  port_value: 80
      http2_protocol_options:
        initial_stream_window_size: 65536 # 64 KiB
        initial_connection_window_size: 1048576 # 1 MiB
    - name: cluster_greeter_server
      "@type": type.googleapis.com/envoy.config.cluster.v3.Cluster
      connect_timeout: 0.2s
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: cluster_greeter_server
        endpoints:
        - lb_endpoints:
          - endpoint:
              address:
                socket_address:
                  address: greeter-server.examples.svc.cluster.local
                  port_value: 80
      http2_protocol_options:
        initial_stream_window_size: 65536 # 64 KiB
        initial_connection_window_size: 1048576 # 1 MiB
  
  envoy.yaml: |+
    # Configuring envoy as an edge proxy: https://www.envoyproxy.io/docs/envoy/latest/configuration/best_practices/edge.html
    # Configurating grpc-web: https://github.com/grpc/grpc-web/blob/master/net/grpc/gateway/examples/helloworld/envoy.yaml
  
    node:
      id: edgeproxy
      cluster: cluster_edgeproxy
    admin:
      access_log_path: "/dev/null"
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 8000
    dynamic_resources:
      cds_config:
        path: /etc/envoy/cds.yaml
      lds_config:
        path: /etc/envoy/lds.yaml
    overload_manager:
      refresh_interval: 0.25s
      resource_monitors:
      - name: "envoy.resource_monitors.fixed_heap"
        typed_config:
          "@type": type.googleapis.com/envoy.config.resource_monitor.fixed_heap.v2alpha.FixedHeapConfig
          max_heap_size_bytes: 1073741824 # 1 GiB, tune for your system.
      actions:
      - name: "envoy.overload_actions.shrink_heap"
        triggers:
        - name: "envoy.resource_monitors.fixed_heap"
          threshold:
            value: 0.95
      - name: "envoy.overload_actions.stop_accepting_requests"
        triggers:
          - name: "envoy.resource_monitors.fixed_heap"
            threshold:
              value: 0.98
    layered_runtime:
      layers:
      - name: static_layer_0
        static_layer:
          envoy:
            resource_limits:
              listener:
                listener_edgeproxy:
                  connection_limit: 10000
          overload:
            global_downstream_max_connections: 50000
  
  lds.yaml: |+
    resources:
    - name: listener_edgeproxy
      "@type": type.googleapis.com/envoy.config.listener.v3.Listener
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 80
      per_connection_buffer_limit_bytes: 32768 # 32 KiB
      filter_chains:
      - filters:
        - name: envoy.filters.network.http_connection_manager
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
            stat_prefix: listener_edgeproxy
            access_log:
              name: envoy.access_loggers.file
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
                path: /dev/stdout
            use_remote_address: true
            common_http_protocol_options:
              idle_timeout: 3600s # 1 hour
              headers_with_underscores_action: REJECT_REQUEST
            http2_protocol_options:
              max_concurrent_streams: 100
              initial_stream_window_size: 65536 # 64 KiB
              initial_connection_window_size: 1048576 # 1 MiB
            # must be disabled for long-lived and streaming requests
            stream_idle_timeout: 300s # 5 mins, must be disabled for long-lived and streaming requests
            request_timeout: 300s # 5 mins, must be disabled for long-lived and streaming requests
            route_config:
              name: route_edgeproxy
              virtual_hosts:
              - name: route_edgeproxy
                domains:
                - "*"
                routes:
                - match:
                    prefix: '/libra.v1.User/Login'
                    grpc: {}
                  route:
                    cluster: cluster_librad_v1
                    idle_timeout: 15s # must be disabled for long-lived and streaming requests
                  typed_per_filter_config:
                    envoy.filters.http.ext_authz:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute
                      disabled: true
                - match:
                    safe_regex:
                      google_re2: {}
                      regex: '/libra\.v1\.(User|Role)/.*'
                    grpc: {}
                  route:
                    cluster: cluster_librad_v1
                    idle_timeout: 15s # must be disabled for long-lived and streaming requests
                - match:
                    prefix: '/helloworld.Greeter/'
                    grpc: {}
                  route:
                    cluster: cluster_greeter_server
                    idle_timeout: 15s # must be disabled for long-lived and streaming requests
            http_filters:
            - name: envoy.filters.http.ext_authz
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthz
                grpc_service:
                  envoy_grpc:
                    cluster_name: cluster_librad_v1
                  initial_metadata:
                  - key: "x-libra-auth-by"
                    value: "token"
                  timeout: 0.2s
                transport_api_version: V3
            - name: envoy.filters.http.router
---
# Source: libra/charts/librad/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: librad-0-0-1
  namespace: libra
data:
  librad.yaml: |+
    bind: ':80'
    services:
      registry:
        auth:
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/1'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/1'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/1'
        nonce:
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/2'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/2'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/2'
        mongo: 'mongodb://mongo-0.mongo.dev.svc.cluster.local:27017'
      database:
        database: &database
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/3'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/3'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/3'
          mongo: 'mongodb://mongo-1.mongo.dev.svc.cluster.local:27017'
        mailbox: &mailbox
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/4'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/4'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/4'
          mongo: 'mongodb://mongo-2.mongo.dev.svc.cluster.local:27017'
        distlock:
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/5'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/5'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/5'
          ttl: '10s'
      syncer:
        tasks:
        - name: db
          <<: *database
        - name: mb
          <<: *mailbox
      ranking:
        bubblechart:
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/6'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/6'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/6'
        leaderboard:
          redis:
            - 'redis://redis-0.redis.dev.svc.cluster.local:6379/7'
            - 'redis://redis-1.redis.dev.svc.cluster.local:6379/7'
            - 'redis://redis-2.redis.dev.svc.cluster.local:6379/7'
---
# Source: libra/charts/apiproxy/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: apiproxy
  namespace: libra
  labels:
    helm.sh/chart: apiproxy-0.1.0
    app.kubernetes.io/name: apiproxy
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/managed-by: Helm
spec:
  type: NodePort
  ports:
    - name: http
      port: 80
      targetPort: http
      protocol: TCP
      nodePort: 31080
  selector:
    app.kubernetes.io/name: apiproxy
    app.kubernetes.io/instance: RELEASE-NAME
---
# Source: libra/charts/edgeproxy/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: edgeproxy
  namespace: libra
  labels:
    helm.sh/chart: edgeproxy-0.1.0
    app.kubernetes.io/name: edgeproxy
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/managed-by: Helm
  annotations:
    # use existed tencent cloud CLB to expose services
    service.kubernetes.io/tke-existed-lbid: lb-xxxxxxxx
spec:
  type: NodePort
  ports:
    - name: http
      port: 80
      targetPort: 80
      protocol: TCP
      nodePort: 30080
  selector:
    app.kubernetes.io/name: edgeproxy
    app.kubernetes.io/instance: RELEASE-NAME
---
# Source: libra/charts/librad/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: librad-0-0-1
  namespace: libra
  labels:
    helm.sh/chart: librad-0.1.0
    app.kubernetes.io/name: librad
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/version: "0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 80
      targetPort: http
      protocol: TCP
  selector:
    app.kubernetes.io/name: librad
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/version: "0.0.1"
---
# Source: libra/charts/apiproxy/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: apiproxy
  namespace: libra
  labels:
    helm.sh/chart: apiproxy-0.1.0
    app.kubernetes.io/name: apiproxy
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: apiproxy
      app.kubernetes.io/instance: RELEASE-NAME
  template:
    metadata:
      labels:
        app.kubernetes.io/name: apiproxy
        app.kubernetes.io/instance: RELEASE-NAME
    spec:
      containers:
        - name: "proxy"
          image: envoyproxy/envoy-alpine:v1.16.4
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
            - containerPort: 8000
              protocol: TCP
          resources:
            null
          volumeMounts:
            - name: config
              mountPath: /etc/envoy
              readOnly: true
        # Configmap mounted volume is implemented as symlinks.
        # But envoy watch file move by inotify, the linked file change
        # would not trigger reload.
        # So that, a helper must exist to watch and move configmap
        # files to envoy directly.
        - name: "helper"
          image: instrumentisto/rsync-ssh:latest
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh","-c","while true; do rsync -dLptgo --delete /tmp/envoy/ /etc/envoy/ && sleep 1 || break; done"]
          volumeMounts:
            - name: config
              mountPath: /etc/envoy
            - name: source
              mountPath: /tmp/envoy
      initContainers:
        # to make sure envoy configurations exist when proxy start
        - name: "initializer"
          image: instrumentisto/rsync-ssh:latest
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh","-c","rsync -dLptgo --delete /tmp/envoy/ /etc/envoy/"]
          volumeMounts:
            - name: config
              mountPath: /etc/envoy
            - name: source
              mountPath: /tmp/envoy
      volumes:
        - name: config
          emptyDir: {}
        - name: source
          configMap:
            name: apiproxy
---
# Source: libra/charts/edgeproxy/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: edgeproxy
  namespace: libra
  labels:
    helm.sh/chart: edgeproxy-0.1.0
    app.kubernetes.io/name: edgeproxy
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: edgeproxy
      app.kubernetes.io/instance: RELEASE-NAME
  template:
    metadata:
      labels:
        app.kubernetes.io/name: edgeproxy
        app.kubernetes.io/instance: RELEASE-NAME
    spec:
      containers:
        - name: "proxy"
          image: envoyproxy/envoy-alpine:v1.16.4
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 80
              protocol: TCP
            - containerPort: 8000
              protocol: TCP
          resources:
            {}
          volumeMounts:
          - name: config
            mountPath: /etc/envoy
            readOnly: true
        - name: "helper"
          image: instrumentisto/rsync-ssh:latest
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh","-c","while true; do rsync -dLptgo --delete /tmp/envoy/ /etc/envoy/ && sleep 1 || break; done"]
          volumeMounts:
            - name: config
              mountPath: /etc/envoy
            - name: source
              mountPath: /tmp/envoy
      initContainers:
        - name: "initalizer"
          image: instrumentisto/rsync-ssh:latest
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh","-c","rsync -dLptgo --delete /tmp/envoy/ /etc/envoy/"]
          volumeMounts:
            - name: config
              mountPath: /etc/envoy
            - name: source
              mountPath: /tmp/envoy
      volumes:
        - name: config
          emptyDir: {}
        - name: source
          configMap:
            name: edgeproxy
---
# Source: libra/charts/librad/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: librad-0-0-1
  namespace: libra
  labels:
    helm.sh/chart: librad-0.1.0
    app.kubernetes.io/name: librad
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/version: "0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: librad
      app.kubernetes.io/instance: RELEASE-NAME
      app.kubernetes.io/version: "0.0.1"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: librad
        app.kubernetes.io/instance: RELEASE-NAME
        app.kubernetes.io/version: "0.0.1"
    spec:
      containers:
        - name: "librad"
          image: onemore/librad:0.0.1
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          args: ["-e","syncer"]
          resources:
            null
          volumeMounts:
            - name: librad
              mountPath: /etc/librad.yaml
              subPath: librad.yaml
              readOnly: true
      volumes:
        - name: librad
          configMap:
            name: librad-0-0-1
---
# Source: libra/charts/syncer/templates/statefulset.yaml
# Syncer同时最多只能有一个实例运行，因此必须保证：
# kind: StatefulSet  保证在前一个实例彻底关闭前不会有新实例运行
# spec.replicas: 1   保证只有一个实例在运行

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: syncer
  namespace: libra
  labels:
    helm.sh/chart: syncer-0.1.0
    app.kubernetes.io/name: syncer
    app.kubernetes.io/instance: RELEASE-NAME
    app.kubernetes.io/version: "0.0.2"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1 # MUST BE 1
  selector:
    matchLabels:
      app.kubernetes.io/name: syncer
      app.kubernetes.io/instance: RELEASE-NAME
      app.kubernetes.io/version: "0.0.2"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: syncer
        app.kubernetes.io/instance: RELEASE-NAME
        app.kubernetes.io/version: "0.0.2"
    spec:
      containers:
        - name: syncer
          image: onemore/librad:0.0.2
          imagePullPolicy: IfNotPresent
          args: ["-i", "syncer"]
          volumeMounts:
          - name: librad
            mountPath: /etc/librad.yaml
            subPath: librad.yaml
            readOnly: true
      volumes:
        - name: librad
          configMap:
            name: librad-0-0-2
